name: 'Run E2E Tests'
description: 'Execute end-to-end tests against running Waterfall application'

inputs:
  test_scope:
    description: 'Scope of tests to run (build|publish|full)'
    required: false
    default: 'build'
  web_url:
    description: 'URL of the running application'
    required: false
    default: 'https://localhost'
  timeout:
    description: 'Timeout for tests in seconds'
    required: false
    default: '300'

runs:
  using: 'composite'
  steps:
    - name: Clone E2E Test Repository
      shell: bash
      run: |
        echo "üß™ Cloning E2E test repository..."
        git clone https://github.com/bengeek06/e2e-waterfall.git e2e-waterfall
        cd e2e-waterfall
        echo "‚úÖ E2E repository cloned"

    - name: Setup Python environment
      shell: bash
      run: |
        cd e2e-waterfall
        echo "üêç Setting up Python environment..."
        python -m venv venv
        source venv/bin/activate
        pip install --no-cache-dir -r requirements.txt
        echo "‚úÖ Python environment ready"

    - name: Install Chrome for Selenium
      shell: bash
      run: |
        echo "üåê Installing Chrome for Selenium tests..."
        sudo apt-get update -qq
        sudo apt-get install -y chromium-browser
        chromium --version
        echo "‚úÖ Chrome installed"

    - name: Configure test environment
      shell: bash
      run: |
        echo "‚öôÔ∏è Configuring test environment..."
        
        # Create .env.test file with proper configuration in e2e-waterfall directory
        cd e2e-waterfall
        cat > .env.test << EOF
        WEB_URL=https://localhost
        COMPANY_NAME=E2ETestCompany
        LOGIN=e2e@test.com
        PASSWORD=E2ETestPassword123!
        LOG_LEVEL=INFO
        EOF
        
        # Export as environment variables for immediate use
        export WEB_URL=https://localhost
        export COMPANY_NAME=E2ETestCompany
        export LOGIN=e2e@test.com
        export PASSWORD=E2ETestPassword123!
        export LOG_LEVEL=INFO
        
        # Also add to GitHub Actions environment for persistence
        echo "WEB_URL=https://localhost" >> $GITHUB_ENV
        echo "COMPANY_NAME=E2ETestCompany" >> $GITHUB_ENV
        echo "LOGIN=e2e@test.com" >> $GITHUB_ENV
        echo "PASSWORD=E2ETestPassword123!" >> $GITHUB_ENV
        echo "LOG_LEVEL=INFO" >> $GITHUB_ENV
        
        echo "‚úÖ Environment configured:"
        echo "  - Application URL: https://localhost"
        echo "  - Test Company: E2ETestCompany" 
        echo "  - Test User: e2e@test.com"
        echo "  - Log Level: INFO"

    - name: Wait for application initialization
      shell: bash
      run: |
        echo "‚è≥ Waiting for application to be ready..."
        
        # Wait for health endpoint to be available
        timeout 120s bash -c 'until curl -k -f https://localhost/health; do echo "Waiting for health endpoint..."; sleep 5; done'
        
        echo "‚úÖ Application health endpoint is ready"
        
        # Wait a bit more for full initialization
        echo "‚è≥ Waiting for application initialization (30s)..."
        sleep 30
        echo "‚úÖ Application should be fully ready"

    - name: Run E2E Tests
      shell: bash
      run: |
        cd e2e-waterfall
        source venv/bin/activate
        
        echo "üß™ Running E2E tests (scope: ${{ inputs.test_scope }})..."
        echo "üéØ Note: Application initialization handled automatically by pytest fixtures"
        
        # Run pytest with the working conftest.py fixtures (ensure_app_initialized will run automatically)
        if [ "${{ inputs.test_scope }}" = "build" ]; then
          echo "Running build validation tests..."
          python -m pytest api/auth/ api/*/test_*system.py -v --tb=short --maxfail=3
        elif [ "${{ inputs.test_scope }}" = "publish" ]; then
          echo "Running comprehensive tests..."  
          python -m pytest api/ ui/login/ -v --tb=short --maxfail=5
        else
          echo "Running full test suite..."
          python -m pytest api/ ui/ -v --tb=short --maxfail=5
        fi

    - name: Upload Test Results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: e2e-test-results-${{ inputs.test_scope }}
        path: |
          e2e-waterfall/logs/
          e2e-waterfall/screenshots/
        retention-days: 7